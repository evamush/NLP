{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "Latex Macros\n",
    "-->\n",
    "$$\n",
    "\\newcommand{\\bar}{\\,|\\,}\n",
    "\\newcommand{\\Xs}{\\mathcal{X}}\n",
    "\\newcommand{\\Ys}{\\mathcal{Y}}\n",
    "\\newcommand{\\y}{\\mathbf{y}}\n",
    "\\newcommand{\\weights}{\\mathbf{w}}\n",
    "\\newcommand{\\balpha}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\bbeta}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\aligns}{\\mathbf{a}}\n",
    "\\newcommand{\\align}{a}\n",
    "\\newcommand{\\source}{\\mathbf{s}}\n",
    "\\newcommand{\\target}{\\mathbf{t}}\n",
    "\\newcommand{\\ssource}{s}\n",
    "\\newcommand{\\starget}{t}\n",
    "\\newcommand{\\repr}{\\mathbf{f}}\n",
    "\\newcommand{\\repry}{\\mathbf{g}}\n",
    "\\newcommand{\\x}{\\mathbf{x}}\n",
    "\\newcommand{\\prob}{p}\n",
    "\\newcommand{\\vocab}{V}\n",
    "\\newcommand{\\params}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\param}{\\theta}\n",
    "\\DeclareMathOperator{\\perplexity}{PP}\n",
    "\\DeclareMathOperator{\\argmax}{argmax}\n",
    "\\DeclareMathOperator{\\argmin}{argmin}\n",
    "\\newcommand{\\train}{\\mathcal{D}}\n",
    "\\newcommand{\\counts}[2]{\\#_{#1}(#2) }\n",
    "\\newcommand{\\length}[1]{\\text{length}(#1) }\n",
    "\\newcommand{\\indi}{\\mathbb{I}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "## Introduction\n",
    "In this assignment you will build the first stage of a biomedical event extractor. Biomedical events are state changes of biomolecules. For example, if you have a protein and you add a phosphate (PO4) group to it, this is referred to as a phosphorylation event. Many papers in the biomedical literature mention such events. The grand goal of biomedical event extraction is to teach machines how to read this literature and produce structured representations of biomedical events that biomedical researchers can query effectively. This task has received considerable attention in the NLP literature, and is the topic of a biennial [shared task](http://2011.bionlp-st.org/). We will use the data from this task as starting point for this assignment.   \n",
    "\n",
    "To illustrate biomedical event extraction, let us consider an example. From the sentence \n",
    "\n",
    "> **phosphorylation** of TRAF2 **inhibits** **binding** to the CD40 domain\n",
    "\n",
    "we could extract the structure \n",
    "\n",
    "> Negative_Regulation(Phosphorylation(TRAF2), Binding(TRAF2, CD40)\n",
    "\n",
    "and store it in a database. Someone can then query this database, for example, to figure out all ways to prevent binding of TRAF2 to CD40.\n",
    "\n",
    "The task is often divided into two steps. First you need to find **trigger** words in the sentence that correspond to biomedical events, and determine their event type *label*. For example, in the above sentence \"phosphorylation\" is a trigger word for an event of type \"Phosphorylation\", \"inhibits\" a trigger word for a \"Negative Regulation\" event, and \"binding\" a trigger for a \"Binding\" event. Notice that sometimes the type labels are obvious, but often they are not. Also note that the label of a word could be \"None\". For example, the word \"of\" in the above sentence has the label \"None\".  \n",
    "\n",
    "The second step requires the extractor to produce **argument relations** between event triggers and protein mentions or other event triggers. For example, in the above case the argument of \"phosphorylation\" is \"TRAF2\", and one argument of \"inhibits\" is \"phosphorylation of TRAF2\" whereas the other is \"binding to the CD40 domain\". In this assignment you **do not have to do this**. We will focus on the event trigger detection problem exclusively. \n",
    "\n",
    "## Goal\n",
    "Your goal is to develop an event trigger labeler. This extractor is given a sentence and a candidate token. Both constitute the input $\\x$. One such input could be: \n",
    "\n",
    "> $\\x$: phosphorylation of TRAF2 **inhibits** binding to the CD40 domain\n",
    "\n",
    "The goal is to predict the label $y$ of the candidate event trigger. In the above case the label would be $y=\\text{Negative_Regulation}$. \n",
    "\n",
    "Some candidates may not refer to event triggers at all. For example:\n",
    "\n",
    "> $\\x$: phosphorylation **of** TRAF2 inhibits binding to the CD40 domain\n",
    "\n",
    "In such cases the label is $y=\\text{None}$.\n",
    "\n",
    "## Resources\n",
    "To develop your model you have access to:\n",
    "\n",
    "* The data in `data/bionlp/train`. This data can be split into training and dev set (as done below), or used for cross-validation.\n",
    "* Helper code stored in the python module [bio.py](/edit/statnlpbook/bio.py).\n",
    "* Libraries on the [docker image](https://github.com/uclmr/stat-nlp-book/blob/python/Dockerfile) which contains everything in [this image](https://github.com/jupyter/docker-stacks/tree/master/scipy-notebook), including scikit-learn and tensorflow. \n",
    "\n",
    "As we have to run the notebooks of all students, and because writing efficient code is important, **your notebook should run in 5 minutes at most**, on your machine. Further comments:\n",
    "\n",
    "* We have tested a possible solution on the Azure VMs and it ran in about 30s, so it is possible to train a reasonable model on the data in reasonable time. If you find training times too long for your development cycle you can reduce the training set size. Once you have found a good solution you can increase the size again. Caveat: model parameters tuned on a smaller dataset may not be optimal for a larger training set.\n",
    "\n",
    "* Try to run your parameter optimisation offline, such that in your answer notebook the best parameters are already set and don't need to be searched. Include your optimisation code in the notebook, but don't call it at each notebook run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hint\n",
    "While you do not need to predict the arguments of an event, it is important to understand how trigger labels relate to the syntactic and semantic arguments of the trigger word. Features that can capture this relation might help you in improving the result. Do inspect the data and try to get an understanding of it. That said, you don't have to be a biomedical expert to do well in this task. A few of the best results on the task were achieved by NLP researchers without any biomedical experience. They would, however, still inspect the data carefully.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Instructions\n",
    "It is important that this file is placed in the **correct directory**. It will not run otherwise. The correct directory is\n",
    "\n",
    "    DIRECTORY_OF_YOUR_BOOK/assignments/2017/assignment2/problem/\n",
    "    \n",
    "where `DIRECTORY_OF_YOUR_BOOK` is a placeholder for the directory you downloaded the book to. After you placed it there, **rename the file** to your UCL ID (of the form `ucxxxxx`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Instructions\n",
    "This notebook will be used by you to provide your solution, and by us to both assess your solution and enter your marks. It contains three types of sections:\n",
    "\n",
    "1. **Setup** Sections: these sections set up code and resources for assessment. **Do not edit, move nor copy these cells**.\n",
    "2. **Assessment** Sections: these sections are used for both evaluating the output of your code, and for markers to enter their marks. **Do not edit, move, nor copy these cells**.\n",
    "3. **Task** Sections: these sections require your solutions. They may contain stub code, and you are expected to edit this code. For free text answers simply edit the markdown field.  \n",
    "\n",
    "**If you edit, move or copy any of the setup, assessments and mark cells, you will be penalised with -10 points**.\n",
    "\n",
    "Note that you are free to **create additional notebook cells** within a task section. \n",
    "\n",
    "Please **do not share** this assignment publicly, by uploading it online, emailing it to friends etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "To submit your solution:\n",
    "\n",
    "* Make sure that your solution is fully contained in this notebook. \n",
    "* Make sure that your solution runs linearly from start to end (no execution hops). We will run your notebook in that order.\n",
    "* **If running your notebook produces a trivially fixable error that we spot, we will correct it and penalise you with -10 points. Otherwise you will get 0 points for that solution.**\n",
    "* **Rename this notebook to your UCL ID** (of the form \"ucxxxxx\"), if you have not already done so. ** Failure to do so will result in -1 point.**\n",
    "* Download the notebook in Jupyter via *File -> Download as -> Notebook (.ipynb)*.\n",
    "* Upload the notebook to the Moodle submission site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 1</font>: Load Libraries\n",
    "This cell loads libraries important for evaluation and assessment of your model. **Do not change, move or copy it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "#! SETUP 1 - DO NOT CHANGE, MOVE NOR COPY\n",
    "import sys, os\n",
    "_snlp_book_dir = \"../../../../\"\n",
    "sys.path.append(_snlp_book_dir) \n",
    "import math\n",
    "from collections import defaultdict\n",
    "import statnlpbook.bio as bio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 2</font>: Load Training Data\n",
    "\n",
    "This cell loads the training data. **Do not edit this setup section, nor copy it**. Instead refer to the variables in your own code, and slice and dice them as you see fit (but do not change their values). For example, no one will stop you from introducing, in the corresponding task section, `my_event_train` and `my_event_dev` variables that split the data into different folds.   \n",
    "\n",
    "Notice that the data is loaded from `json` files like [this one](/edit/data/bionlp/train/PMC-1310901-00-TIAB.json). Generally, you do not need to understand this format, as we provide loading functions that produce more convenient data structures shown below. But do feel free to investigate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! SETUP 2 - DO NOT CHANGE, MOVE NOR COPY\n",
    "train_path = _snlp_book_dir + \"data/bionlp/train\"\n",
    "event_corpus = bio.load_assignment2_training_data(train_path)\n",
    "event_train = event_corpus[:len(event_corpus)//4 * 3]\n",
    "event_dev = event_corpus[len(event_corpus)//4 * 3:]\n",
    "assert(len(event_train)==53988)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures\n",
    "The data comes in the form of pairs consisting of `EventCandidate` objects and their trigger labels. The `EventCandidate` class can be found in [bio.py](/edit/statnlpbook/bio.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<statnlpbook.bio.EventCandidate at 0x7fbb43f80ef0>, 'Negative_regulation')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_candidate, label = event_corpus[0]\n",
    "(event_candidate, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Event candidate objects specify the classification problem. They consist of a sentence `sent` and the position `trigger_index` of the trigger candidate word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Down-regulation of interferon regulatory factor 4 gene expression in leukemic cells due to hypermethylation of CpG motifs in the promoter region Although the bcr -abl translocation has been shown to be the causative genetic aberration in chronic myeloid leukemia ( CML ) , there is mounting evidence that the deregulation of other genes , such as the transcription factor interferon regulatory factor 4 ( IRF-4 ) , is also implicated in the pathogenesis of CML ."
      ],
      "text/plain": [
       "<statnlpbook.bio.Sentence at 0x7fbb44464780>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_candidate.sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_candidate.trigger_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Event candidates also have a set of candidate arguments. These point to token spans (index of first token, inclusive, index of last token, exclusive) in the sentence that may or may not be *arguments* of the event. In the full event extraction task one needs to predict which of these candidates are true arguments of the events. However, here we will ignore this task, and give you only the information what candidates exist, not what their labels are. Note that this information can still be **very important** to understand what type of event the candidate corresponds to, if any. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 6), (23, 24), (24, 25), (59, 63)]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_candidate.argument_candidate_spans[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compactly visualise the complete candidate using `bio.render_event`, as shown below. Here the green span corresponds to the token at the trigger index. The spans in red brackets correspond to the argument candidates. The blue spans are protein mentions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font color='green'>Down-regulation</font> <font color='red'>[</font>of<font color='red'>]</font> <font color='red'>[</font><font color='blue'>[interferon regulatory factor 4]</font><font color='red'>]</font> gene <font color='red'>[</font>expression<font color='red'>]</font> in leukemic cells <font color='red'>[</font>due<font color='red'>]</font> <font color='red'>[</font>to<font color='red'>]</font> hypermethylation <font color='red'>[</font>of<font color='red'>]</font> CpG motifs in the <font color='red'>[</font>promoter<font color='red'>]</font> region Although the <font color='red'>[</font><font color='blue'>[bcr]</font><font color='red'>]</font> <font color='red'>[</font><font color='blue'>[-abl]</font><font color='red'>]</font> <font color='red'>[</font>translocation<font color='red'>]</font> has been shown <font color='red'>[</font>to<font color='red'>]</font> be the causative genetic <font color='red'>[</font>aberration<font color='red'>]</font> in chronic myeloid leukemia ( CML ) , there is mounting evidence <font color='red'>[</font>that<font color='red'>]</font> the <font color='red'>[</font>deregulation<font color='red'>]</font> <font color='red'>[</font>of<font color='red'>]</font> other genes , such as the <font color='red'>[</font>transcription<font color='red'>]</font> <font color='red'>[</font>factor<font color='red'>]</font> <font color='red'>[</font><font color='blue'>[interferon regulatory factor 4]</font><font color='red'>]</font> ( <font color='red'>[</font><font color='blue'>[IRF-4]</font><font color='red'>]</font> ) , is also <font color='red'>[</font>implicated<font color='red'>]</font> in the pathogenesis <font color='red'>[</font>of<font color='red'>]</font> CML ."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio.render_event(event_candidate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences\n",
    "The sentence object of an event candidate provides additional information about the sentence, such as what spans are proteins, what Part-of-Speech labels the tokens have, and a dependency parse of the sentence. First, the `tokens` field of a sentence provides useful features of tokens: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'begin': 0,\n",
       " 'end': 15,\n",
       " 'index': 0,\n",
       " 'pos': 'NN',\n",
       " 'stem': 'Down-regul',\n",
       " 'word': 'Down-regulation'}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_candidate.sent.tokens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dependencies` field stores lexical dependencies between words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'head': 44, 'label': 'nsubj', 'mod': 0},\n",
       " {'head': 4, 'label': 'nn', 'mod': 2}]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_candidate.sent.dependencies[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can render the dependency graph of a sentence like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div id='displacy33' style=\"overflow: scroll; width: 5000px;\"></div>\n",
       "    <script>\n",
       "    $(function() {\n",
       "    requirejs.config({\n",
       "        paths: {\n",
       "            'displaCy': ['/files/node_modules/displacy/displacy'],\n",
       "                                                  // strip .js ^, require adds it back\n",
       "        },\n",
       "    });\n",
       "    require(['displaCy'], function() {\n",
       "        console.log(\"Loaded :)\");\n",
       "        const displacy = new displaCy('http://localhost:8000', {\n",
       "            container: '#displacy33',\n",
       "            format: 'spacy',\n",
       "            distance: 150,\n",
       "            offsetX: 0,\n",
       "            wordSpacing: 20,\n",
       "            arrowSpacing: 3,\n",
       "\n",
       "        });\n",
       "        const parse = {\n",
       "            arcs: [{\"dir\": \"left\", \"start\": 0, \"label\": \"nsubj\", \"end\": 44}, {\"dir\": \"left\", \"start\": 2, \"label\": \"nn\", \"end\": 4}, {\"dir\": \"left\", \"start\": 3, \"label\": \"amod\", \"end\": 4}, {\"dir\": \"left\", \"start\": 4, \"label\": \"nn\", \"end\": 7}, {\"dir\": \"right\", \"start\": 4, \"label\": \"num\", \"end\": 5}, {\"dir\": \"left\", \"start\": 6, \"label\": \"nn\", \"end\": 7}, {\"dir\": \"right\", \"start\": 0, \"label\": \"prep_of\", \"end\": 7}, {\"dir\": \"left\", \"start\": 9, \"label\": \"amod\", \"end\": 10}, {\"dir\": \"right\", \"start\": 7, \"label\": \"prep_in\", \"end\": 10}, {\"dir\": \"right\", \"start\": 7, \"label\": \"prep_due_to\", \"end\": 13}, {\"dir\": \"left\", \"start\": 15, \"label\": \"nn\", \"end\": 16}, {\"dir\": \"right\", \"start\": 13, \"label\": \"prep_of\", \"end\": 16}, {\"dir\": \"left\", \"start\": 18, \"label\": \"det\", \"end\": 20}, {\"dir\": \"left\", \"start\": 19, \"label\": \"nn\", \"end\": 20}, {\"dir\": \"right\", \"start\": 0, \"label\": \"prep_in\", \"end\": 20}, {\"dir\": \"left\", \"start\": 21, \"label\": \"mark\", \"end\": 28}, {\"dir\": \"left\", \"start\": 22, \"label\": \"det\", \"end\": 25}, {\"dir\": \"left\", \"start\": 23, \"label\": \"nn\", \"end\": 25}, {\"dir\": \"left\", \"start\": 24, \"label\": \"nn\", \"end\": 25}, {\"dir\": \"left\", \"start\": 25, \"label\": \"nsubjpass\", \"end\": 28}, {\"dir\": \"left\", \"start\": 25, \"label\": \"xsubj\", \"end\": 34}, {\"dir\": \"left\", \"start\": 26, \"label\": \"aux\", \"end\": 28}, {\"dir\": \"left\", \"start\": 27, \"label\": \"auxpass\", \"end\": 28}, {\"dir\": \"left\", \"start\": 28, \"label\": \"advcl\", \"end\": 44}, {\"dir\": \"left\", \"start\": 29, \"label\": \"aux\", \"end\": 34}, {\"dir\": \"left\", \"start\": 30, \"label\": \"cop\", \"end\": 34}, {\"dir\": \"left\", \"start\": 31, \"label\": \"det\", \"end\": 34}, {\"dir\": \"left\", \"start\": 32, \"label\": \"amod\", \"end\": 34}, {\"dir\": \"left\", \"start\": 33, \"label\": \"amod\", \"end\": 34}, {\"dir\": \"right\", \"start\": 28, \"label\": \"xcomp\", \"end\": 34}, {\"dir\": \"left\", \"start\": 36, \"label\": \"amod\", \"end\": 38}, {\"dir\": \"left\", \"start\": 37, \"label\": \"amod\", \"end\": 38}, {\"dir\": \"right\", \"start\": 34, \"label\": \"prep_in\", \"end\": 38}, {\"dir\": \"right\", \"start\": 38, \"label\": \"abbrev\", \"end\": 40}, {\"dir\": \"left\", \"start\": 43, \"label\": \"expl\", \"end\": 44}, {\"dir\": \"left\", \"start\": 45, \"label\": \"amod\", \"end\": 46}, {\"dir\": \"right\", \"start\": 44, \"label\": \"nsubj\", \"end\": 46}, {\"dir\": \"left\", \"start\": 47, \"label\": \"complm\", \"end\": 69}, {\"dir\": \"left\", \"start\": 48, \"label\": \"det\", \"end\": 49}, {\"dir\": \"left\", \"start\": 49, \"label\": \"nsubjpass\", \"end\": 69}, {\"dir\": \"left\", \"start\": 51, \"label\": \"amod\", \"end\": 52}, {\"dir\": \"right\", \"start\": 49, \"label\": \"prep_of\", \"end\": 52}, {\"dir\": \"left\", \"start\": 56, \"label\": \"det\", \"end\": 61}, {\"dir\": \"left\", \"start\": 57, \"label\": \"nn\", \"end\": 61}, {\"dir\": \"left\", \"start\": 58, \"label\": \"nn\", \"end\": 61}, {\"dir\": \"left\", \"start\": 59, \"label\": \"nn\", \"end\": 61}, {\"dir\": \"left\", \"start\": 60, \"label\": \"amod\", \"end\": 61}, {\"dir\": \"right\", \"start\": 52, \"label\": \"prep_such_as\", \"end\": 61}, {\"dir\": \"right\", \"start\": 61, \"label\": \"num\", \"end\": 62}, {\"dir\": \"right\", \"start\": 61, \"label\": \"abbrev\", \"end\": 64}, {\"dir\": \"left\", \"start\": 67, \"label\": \"auxpass\", \"end\": 69}, {\"dir\": \"left\", \"start\": 68, \"label\": \"advmod\", \"end\": 69}, {\"dir\": \"right\", \"start\": 46, \"label\": \"ccomp\", \"end\": 69}, {\"dir\": \"left\", \"start\": 71, \"label\": \"det\", \"end\": 72}, {\"dir\": \"right\", \"start\": 69, \"label\": \"prep_in\", \"end\": 72}, {\"dir\": \"right\", \"start\": 72, \"label\": \"prep_of\", \"end\": 74}],\n",
       "            words: [{\"text\": \"Down-regulation\", \"tag\": \"NN\"}, {\"text\": \"of\", \"tag\": \"IN\"}, {\"text\": \"interferon\", \"tag\": \"NN\"}, {\"text\": \"regulatory\", \"tag\": \"JJ\"}, {\"text\": \"factor\", \"tag\": \"NN\"}, {\"text\": \"4\", \"tag\": \"CD\"}, {\"text\": \"gene\", \"tag\": \"NN\"}, {\"text\": \"expression\", \"tag\": \"NN\"}, {\"text\": \"in\", \"tag\": \"IN\"}, {\"text\": \"leukemic\", \"tag\": \"JJ\"}, {\"text\": \"cells\", \"tag\": \"NNS\"}, {\"text\": \"due\", \"tag\": \"IN\"}, {\"text\": \"to\", \"tag\": \"TO\"}, {\"text\": \"hypermethylation\", \"tag\": \"NN\"}, {\"text\": \"of\", \"tag\": \"IN\"}, {\"text\": \"CpG\", \"tag\": \"NN\"}, {\"text\": \"motifs\", \"tag\": \"NNS\"}, {\"text\": \"in\", \"tag\": \"IN\"}, {\"text\": \"the\", \"tag\": \"DT\"}, {\"text\": \"promoter\", \"tag\": \"NN\"}, {\"text\": \"region\", \"tag\": \"NN\"}, {\"text\": \"Although\", \"tag\": \"IN\"}, {\"text\": \"the\", \"tag\": \"DT\"}, {\"text\": \"bcr\", \"tag\": \"NN\"}, {\"text\": \"-abl\", \"tag\": \"NN\"}, {\"text\": \"translocation\", \"tag\": \"NN\"}, {\"text\": \"has\", \"tag\": \"VBZ\"}, {\"text\": \"been\", \"tag\": \"VBN\"}, {\"text\": \"shown\", \"tag\": \"VBN\"}, {\"text\": \"to\", \"tag\": \"TO\"}, {\"text\": \"be\", \"tag\": \"VB\"}, {\"text\": \"the\", \"tag\": \"DT\"}, {\"text\": \"causative\", \"tag\": \"JJ\"}, {\"text\": \"genetic\", \"tag\": \"JJ\"}, {\"text\": \"aberration\", \"tag\": \"NN\"}, {\"text\": \"in\", \"tag\": \"IN\"}, {\"text\": \"chronic\", \"tag\": \"JJ\"}, {\"text\": \"myeloid\", \"tag\": \"JJ\"}, {\"text\": \"leukemia\", \"tag\": \"NN\"}, {\"text\": \"(\", \"tag\": \"-LRB-\"}, {\"text\": \"CML\", \"tag\": \"NN\"}, {\"text\": \")\", \"tag\": \"-RRB-\"}, {\"text\": \",\", \"tag\": \",\"}, {\"text\": \"there\", \"tag\": \"EX\"}, {\"text\": \"is\", \"tag\": \"VBZ\"}, {\"text\": \"mounting\", \"tag\": \"JJ\"}, {\"text\": \"evidence\", \"tag\": \"NN\"}, {\"text\": \"that\", \"tag\": \"IN\"}, {\"text\": \"the\", \"tag\": \"DT\"}, {\"text\": \"deregulation\", \"tag\": \"NN\"}, {\"text\": \"of\", \"tag\": \"IN\"}, {\"text\": \"other\", \"tag\": \"JJ\"}, {\"text\": \"genes\", \"tag\": \"NNS\"}, {\"text\": \",\", \"tag\": \",\"}, {\"text\": \"such\", \"tag\": \"JJ\"}, {\"text\": \"as\", \"tag\": \"IN\"}, {\"text\": \"the\", \"tag\": \"DT\"}, {\"text\": \"transcription\", \"tag\": \"NN\"}, {\"text\": \"factor\", \"tag\": \"NN\"}, {\"text\": \"interferon\", \"tag\": \"NN\"}, {\"text\": \"regulatory\", \"tag\": \"JJ\"}, {\"text\": \"factor\", \"tag\": \"NN\"}, {\"text\": \"4\", \"tag\": \"CD\"}, {\"text\": \"(\", \"tag\": \"-LRB-\"}, {\"text\": \"IRF-4\", \"tag\": \"NN\"}, {\"text\": \")\", \"tag\": \"-RRB-\"}, {\"text\": \",\", \"tag\": \",\"}, {\"text\": \"is\", \"tag\": \"VBZ\"}, {\"text\": \"also\", \"tag\": \"RB\"}, {\"text\": \"implicated\", \"tag\": \"VBN\"}, {\"text\": \"in\", \"tag\": \"IN\"}, {\"text\": \"the\", \"tag\": \"DT\"}, {\"text\": \"pathogenesis\", \"tag\": \"NN\"}, {\"text\": \"of\", \"tag\": \"IN\"}, {\"text\": \"CML\", \"tag\": \"NN\"}, {\"text\": \".\", \"tag\": \".\"}]\n",
       "        };\n",
       "\n",
       "        displacy.render(parse, {\n",
       "            uniqueId: 'render_displacy33'\n",
       "            //color: '#ff0000'\n",
       "        });\n",
       "        return {};\n",
       "    });\n",
       "    });\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio.render_dependencies(event_candidate.sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can learn about the dependency labels in the [Stanford typed dependencies manual](http://nlp.stanford.edu/software/dependencies_manual.pdf). We also provide [lecture notes on dependency parsing](/notebooks/chapters/Transition-based%20dependency%20parsing.ipynb), including various pointers to more information. \n",
    "\n",
    "The `mentions` stores which spans correspond to proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'begin': 2, 'end': 6, 'label': 'Protein'},\n",
       " {'begin': 23, 'end': 24, 'label': 'Protein'},\n",
       " {'begin': 24, 'end': 25, 'label': 'Protein'},\n",
       " {'begin': 59, 'end': 63, 'label': 'Protein'},\n",
       " {'begin': 64, 'end': 65, 'label': 'Protein'}]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_candidate.sent.mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some convenience functions for the sentence to check all the syntactic parents or children of a token, or whether a specific token is within a protein mention. These can be useful when designing features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(44, 'nsubj')], [(7, 'prep_of'), (20, 'prep_in')])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_candidate.sent.parents[0], event_candidate.sent.children[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_candidate.sent.is_protein[3], event_candidate.sent.is_protein[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels\n",
    "It is useful to know the complete set of event labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Binding',\n",
       " 'Gene_expression',\n",
       " 'Localization',\n",
       " 'Negative_regulation',\n",
       " 'None',\n",
       " 'Phosphorylation',\n",
       " 'Positive_regulation',\n",
       " 'Protein_catabolism',\n",
       " 'Regulation',\n",
       " 'Transcription'}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{y for _,y in event_corpus}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 1</font>: Create a Feature Function\n",
    "\n",
    "In this task you will extract a specific feature representation $\\repr(\\x)$ for an event candidate $\\x$. In particular, we want to add as features the syntactic children (modifiers) of the trigger token, together with their syntactic dependency label. A modifier of a token $h$ is a token $m$ that modifies $h$'s meaning. For example, in the noun phrase \"green light\" the adjective \"green\" modifies the noun \"light\". We will refer to the modifier token as the \"child\", and the modified token as \"parent\". Correspondingly, in the dependency graph modifiers are the child nodes of the modified tokens.  \n",
    "\n",
    "The feature function will have to be implemented as a python function that populates a python dictionary with key-value pairs where the key indicates both the word and syntactic label of the child. \n",
    "\n",
    "For example, consider the following event and dependency parse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div id='displacy34' style=\"overflow: scroll; width: 5000px;\"></div>\n",
       "    <script>\n",
       "    $(function() {\n",
       "    requirejs.config({\n",
       "        paths: {\n",
       "            'displaCy': ['/files/node_modules/displacy/displacy'],\n",
       "                                                  // strip .js ^, require adds it back\n",
       "        },\n",
       "    });\n",
       "    require(['displaCy'], function() {\n",
       "        console.log(\"Loaded :)\");\n",
       "        const displacy = new displaCy('http://localhost:8000', {\n",
       "            container: '#displacy34',\n",
       "            format: 'spacy',\n",
       "            distance: 150,\n",
       "            offsetX: 0,\n",
       "            wordSpacing: 20,\n",
       "            arrowSpacing: 3,\n",
       "\n",
       "        });\n",
       "        const parse = {\n",
       "            arcs: [{\"dir\": \"left\", \"start\": 0, \"label\": \"det\", \"end\": 2}, {\"dir\": \"left\", \"start\": 1, \"label\": \"nn\", \"end\": 2}, {\"dir\": \"left\", \"start\": 2, \"label\": \"nsubjpass\", \"end\": 4}, {\"dir\": \"left\", \"start\": 3, \"label\": \"auxpass\", \"end\": 4}, {\"dir\": \"left\", \"start\": 6, \"label\": \"det\", \"end\": 10}, {\"dir\": \"left\", \"start\": 7, \"label\": \"number\", \"end\": 8}, {\"dir\": \"left\", \"start\": 8, \"label\": \"amod\", \"end\": 10}, {\"dir\": \"left\", \"start\": 9, \"label\": \"nn\", \"end\": 10}, {\"dir\": \"right\", \"start\": 4, \"label\": \"prep_on\", \"end\": 10}, {\"dir\": \"left\", \"start\": 12, \"label\": \"auxpass\", \"end\": 13}, {\"dir\": \"right\", \"start\": 4, \"label\": \"dep\", \"end\": 13}, {\"dir\": \"left\", \"start\": 15, \"label\": \"nn\", \"end\": 16}, {\"dir\": \"right\", \"start\": 13, \"label\": \"prep_with\", \"end\": 16}, {\"dir\": \"right\", \"start\": 4, \"label\": \"dep\", \"end\": 18}, {\"dir\": \"right\", \"start\": 13, \"label\": \"conj_and\", \"end\": 18}],\n",
       "            words: [{\"text\": \"The\", \"tag\": \"DT\"}, {\"text\": \"PCR\", \"tag\": \"NN\"}, {\"text\": \"products\", \"tag\": \"NNS\"}, {\"text\": \"were\", \"tag\": \"VBD\"}, {\"text\": \"electrophoresed\", \"tag\": \"VBN\"}, {\"text\": \"on\", \"tag\": \"IN\"}, {\"text\": \"a\", \"tag\": \"DT\"}, {\"text\": \"3\", \"tag\": \"CD\"}, {\"text\": \"%\", \"tag\": \"NN\"}, {\"text\": \"agarose\", \"tag\": \"NN\"}, {\"text\": \"gel\", \"tag\": \"NN\"}, {\"text\": \",\", \"tag\": \",\"}, {\"text\": \"were\", \"tag\": \"VBD\"}, {\"text\": \"stained\", \"tag\": \"VBN\"}, {\"text\": \"with\", \"tag\": \"IN\"}, {\"text\": \"ethidium\", \"tag\": \"NN\"}, {\"text\": \"bromide\", \"tag\": \"NN\"}, {\"text\": \"and\", \"tag\": \"CC\"}, {\"text\": \"photographed\", \"tag\": \"VBN\"}, {\"text\": \".\", \"tag\": \".\"}]\n",
       "        };\n",
       "\n",
       "        displacy.render(parse, {\n",
       "            uniqueId: 'render_displacy34'\n",
       "            //color: '#ff0000'\n",
       "        });\n",
       "        return {};\n",
       "    });\n",
       "    });\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = event_corpus[398][0]\n",
    "bio.render_dependencies(example.sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the goal is to produce a dictionary that maps the strings \"Child: det->The\" and \"Child: nn->PCR\" to 1.0. \n",
    "\n",
    "To solve this task, implement the feature function below. The passed in `result` is a dictionary you need to populate with more entries, and the `event` argument indicates for which event you need to extract the features. We have already populated the function with some initial code that should get you started.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dependency_child_feats(result, event):\n",
    "    \"\"\"\n",
    "    Append to the `result` dictionary features based on the syntactic dependencies of the event trigger word of\n",
    "    `event`. The feature keys should have the form \"Child: [label]->[word]\" where \"[label]\" is the syntactic label\n",
    "    of the syntatic child (e.g. \"det\" in the case above), and \"[word]\" is the word of the syntactic child (e.g. \"The\" \n",
    "    in the case above).\n",
    "    Args:\n",
    "        result: a defaultdict that returns `0.0` by default. \n",
    "        event: the event for which we want to populate the `result` dictionary with dependency features.\n",
    "    Returns:\n",
    "        Nothing, but populates the `result` dictionary. \n",
    "    \"\"\"\n",
    "    index = event.trigger_index # You will need to change this \n",
    "    for child,label in event.sent.children[index]:\n",
    "        word = example.sent.tokens[child]['word']\n",
    "        result[\"Child: \" + label + \"->\" + word ] += 1.0 \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 1</font>: Test Feature Function (20 pts)\n",
    "Here we test whether your feature function populates the given dictionary correctly. If the result passes all three tests you get 10 pts. Of course, solutions that just manually populate the result with the specific key value pairs tested below will receive 0 pts as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! ASSESSMENT 1 - DO NOT CHANGE, MOVE NOR COPY\n",
    "result = defaultdict(float)\n",
    "add_dependency_child_feats(result, example)\n",
    "\n",
    "check_1 = len(result) == 2\n",
    "check_2 = result['Child: det->The'] == 1.0\n",
    "check_3 = result['Child: nn->PCR'] == 1.0\n",
    "(check_1, check_2, check_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Mark</font>:  Your solution to Task 1 is marked with ** __ points**. \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 2</font>: Implement Model\n",
    "\n",
    "You are to implement the `predict_event_labels` function below. This function gets as input a list of event candidate objects, and then returns a sequence of corresponding labels. You can implement this function in any way you like, again utilising any library on the docker image. We have populated the cell and function with a simple implementation that uses the scikit-learn logistic regression model. You can use this as a starting point and focus on implementing better feature functions. You can also start from scratch if you like. \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#count the words in training dataset\n",
    "import numpy as np\n",
    "def cal_term_count(dataset):\n",
    "    term_count = {}\n",
    "    for event,_ in dataset:\n",
    "        for token in event.sent.tokens:\n",
    "            word = token['stem']\n",
    "            if word not in term_count.keys():\n",
    "                term_count[word] = 1\n",
    "            else:\n",
    "                term_count[word] += 1\n",
    "    return term_count\n",
    "\n",
    "count_dict = cal_term_count(event_train)\n",
    "x = sorted(count_dict.items(),key=lambda d:d[1], reverse = True)\n",
    "meaningless = set(np.asarray(x)[:12,0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#TF-IDF\n",
    "corpus = []\n",
    "\n",
    "for event, label in event_train:\n",
    "    sent = \"\"\n",
    "    for span in event.argument_candidate_spans:\n",
    "        for i in range(span[0],span[1]):\n",
    "            if event.sent.tokens[i]['stem'] not in meaningless:\n",
    "                sent = sent + event.sent.tokens[i]['stem'] + \" \"\n",
    "    corpus.append(sent)\n",
    "    \n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "vectorizer = CountVectorizer()  \n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(vectorizer.fit_transform(corpus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# converts labels into integers, and vice versa, needed by scikit-learn.\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# encodes feature dictionaries as numpy vectors, needed by scikit-learn.\n",
    "vectorizer = DictVectorizer()\n",
    "\n",
    "def event_feat(event):\n",
    "    \"\"\"\n",
    "    This feature function returns a dictionary representation of the event candidate. You can improve the model \n",
    "    by improving this feature function.\n",
    "    Args:\n",
    "        event: the `EventCandidate` object to produce a feature dictionary for.\n",
    "    Returns:\n",
    "        a dictionary with feature keys/indices mapped to feature counts.\n",
    "    \"\"\"\n",
    "    result = defaultdict(float)\n",
    "    trigger = event.trigger_index\n",
    "    tokens =  event.sent.tokens\n",
    "    children = event.sent.children\n",
    "    parents = event.sent.parents\n",
    "    mentions = event.sent.mentions\n",
    "    \n",
    "    ###\n",
    "    result['trigger_word=' + tokens[trigger]['word']] += 1.0\n",
    "    result['trigger_word=' + tokens[trigger]['stem']] += 1.0\n",
    "    result['trigger_word=' + tokens[trigger]['pos']] += 1.0\n",
    "    \n",
    "    ###\n",
    "    for child,label in children[trigger]:\n",
    "        word = tokens[child]['word']\n",
    "        result[\"Child: \" + label + \"->\" + word ] += 1.0 \n",
    "        for grandchild,grandlabel in children[child]:\n",
    "            grandword = tokens[grandchild]['word']\n",
    "            result[\"GrandChild: \" + grandlabel + \"->\" + grandword ] += 1.0 \n",
    "            \n",
    "    for parent,label in parents[trigger]:\n",
    "        word = tokens[parent]['word']\n",
    "        result[\"Parents: \" + label + \"->\" + word ] += 1.0 \n",
    "        for grandparent,grandlabel in parents[parent]:\n",
    "            grandword = tokens[grandparent]['word']\n",
    "            result[\"GrandParent: \" + grandlabel + \"->\" + grandword ] += 1.0 \n",
    "    \n",
    "    ###\n",
    "    if tokens[trigger][\"pos\"] != \"IN\" :\n",
    "        word = tokens[trigger][\"word\"]\n",
    "        result[\"trigger is not IN\" + word] += 1.0\n",
    "    elif tokens[trigger][\"pos\"] == \"IN\" :\n",
    "        word = tokens[trigger][\"word\"]\n",
    "        result[\"trigger is IN\" + word] += 1.0\n",
    "\n",
    "    ###\n",
    "    if tokens[trigger+1][\"pos\"]!=\"IN\" :\n",
    "        word = tokens[trigger][\"word\"] + tokens[trigger + 1][\"word\"]\n",
    "        result[\"beside trigger is not IN\" + word] += 1.0\n",
    "    elif tokens[trigger+1][\"pos\"]==\"IN\" :\n",
    "        word = tokens[trigger][\"word\"] + tokens[trigger + 1][\"word\"]\n",
    "        result[\"beside trigger is IN\" + word] += 1.0\n",
    "\n",
    "    if tokens[trigger-1][\"pos\"]!=\"IN\" :\n",
    "        word = tokens[trigger][\"word\"] + tokens[trigger - 1][\"word\"]\n",
    "        result[\"beside trigger is not IN\" + word] += 1.0\n",
    "    elif tokens[trigger-1][\"pos\"]==\"IN\" :\n",
    "        word = tokens[trigger][\"word\"] + tokens[trigger - 1][\"word\"]\n",
    "        result[\"beside trigger is IN\" + word] += 1.0\n",
    "    \n",
    "    ###\n",
    "    result[\"Number of Proteins=\" + str(len(mentions))] += 1.0\n",
    "    \n",
    "    min_distance = float(\"inf\")\n",
    "    for i in range(len(mentions)):\n",
    "        begin = mentions[i][\"begin\"]\n",
    "        end = mentions[i][\"end\"]\n",
    "        label = mentions[i][\"label\"]\n",
    "        word = tokens[trigger]['stem']\n",
    "        ###\n",
    "        if (end == trigger) or (end == trigger - 1) or (begin == trigger + 1) or (begin == trigger + 2):\n",
    "            result[\"Protein lies near \"+ word] += 1.0\n",
    "        else:\n",
    "            result[\"No protein lies near\" + word] += 1.0\n",
    "\n",
    "        if begin > trigger:\n",
    "            if begin - trigger  <= min_distance:\n",
    "                min_distance = begin - trigger \n",
    "       \n",
    "        ###\n",
    "        for j in range(begin,end):\n",
    "            for parent,label in parents[j]:\n",
    "                if parent == trigger:\n",
    "                    result[\"Protein's parent is trigger:\" + label] += 1.0\n",
    "                else:\n",
    "                    result[\"Protein's parent is not a trigger:\" + label] += 1.0\n",
    "\n",
    "\n",
    "            for child,label in children[j]:\n",
    "                if child == trigger:\n",
    "                    result[\"Protein's child is trigger:\" + label] += 1.0\n",
    "                else:\n",
    "                    result[\"Protein's child is not a trigger:\" + label] += 1.0\n",
    "    \n",
    "    ###\n",
    "    result[\"minimum distance between protein and trigger = \" + str(min_distance)] += 1.0\n",
    "    \n",
    "    return result\n",
    "# We convert the event candidates and their labels into vectors and integers, respectively.\n",
    "train_event_x = vectorizer.fit_transform([event_feat(x) for x,_ in event_train])\n",
    "train_event_y = label_encoder.fit_transform([y for _,y in event_train])\n",
    "\n",
    "# Create and train the model. Feel free to experiment with other parameters and learners.\n",
    "lr = LogisticRegression(C=2,class_weight='balanced')\n",
    "lr.fit(train_event_x, train_event_y)\n",
    "\n",
    "def predict_event_labels(event_candidates):\n",
    "    \"\"\"\n",
    "    This function receives a list of `bio.EventCandidate` objects and predicts their labels. \n",
    "    It is currently implemented using scikit-learn, but you are free to replace it with any other\n",
    "    implementation as long as you fulfil its contract.\n",
    "    Args:\n",
    "        event_candidates: A list of `EventCandidate` objects to label.\n",
    "    Returns:\n",
    "        a list of event labels, where the i-th label belongs to the i-th event candidate in the input.\n",
    "    \"\"\"\n",
    "    event_x = vectorizer.transform([event_feat(e) for e in event_candidates])\n",
    "    event_y = label_encoder.inverse_transform(lr.predict(event_x))\n",
    "    return event_y\n",
    "\n",
    "#[event_feat(x) for x,_ in event_train][:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "kf = KFold(n_splits = 5)\n",
    "\n",
    "c = np.linspace(1,5,10)\n",
    "f1_ = np.zeros(10)\n",
    "for i in range(10):\n",
    "    lr = LogisticRegression(C = c[i], class_weight=\"balanced\")\n",
    "    f1 = 0\n",
    "    for train_indice, test_indice in kf.split(train_event_x):\n",
    "        train_x = train_event_x[train_indice]\n",
    "        test_x = train_event_x[test_indice]\n",
    "        train_y = train_event_y[train_indice]\n",
    "        test_y = train_event_y[test_indice]\n",
    "        lr.fit(train_x,train_y)\n",
    "        pre = lr.predict(test_x)\n",
    "        f1 += f1_score(test_y, pre,average = \"macro\")\n",
    "    f1_[i] = f1/5\n",
    "    print(i, \":\", \"F1:\", f1_[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to inspect the performance of your model, and see where it makes errors, both on the training set (to check for underfitting) and the development set. We have provided you with utility functions to help with this inspection. Note that you don't have to use these utilities, or the cells below, but it can help you to improve your model, and also with the error analysis and description of the approach in Task 3. \n",
    "\n",
    "First, we give you a breakdown of precision, recall and F1 on different event types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Guess</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Binding</td>\n",
       "      <td>180</td>\n",
       "      <td>202</td>\n",
       "      <td>0.599010</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>0.633508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gene_expression</td>\n",
       "      <td>377</td>\n",
       "      <td>399</td>\n",
       "      <td>0.786967</td>\n",
       "      <td>0.832891</td>\n",
       "      <td>0.809278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Localization</td>\n",
       "      <td>71</td>\n",
       "      <td>63</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative_regulation</td>\n",
       "      <td>210</td>\n",
       "      <td>233</td>\n",
       "      <td>0.605150</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.636569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phosphorylation</td>\n",
       "      <td>32</td>\n",
       "      <td>37</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.898551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positive_regulation</td>\n",
       "      <td>570</td>\n",
       "      <td>614</td>\n",
       "      <td>0.627036</td>\n",
       "      <td>0.675439</td>\n",
       "      <td>0.650338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Protein_catabolism</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Regulation</td>\n",
       "      <td>188</td>\n",
       "      <td>185</td>\n",
       "      <td>0.562162</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.557641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Transcription</td>\n",
       "      <td>112</td>\n",
       "      <td>105</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.626728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[All]</td>\n",
       "      <td>1761</td>\n",
       "      <td>1864</td>\n",
       "      <td>0.660944</td>\n",
       "      <td>0.699602</td>\n",
       "      <td>0.679724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Label  Gold  Guess  Precision    Recall        F1\n",
       "0              Binding   180    202   0.599010  0.672222  0.633508\n",
       "1      Gene_expression   377    399   0.786967  0.832891  0.809278\n",
       "2         Localization    71     63   0.777778  0.690141  0.731343\n",
       "3  Negative_regulation   210    233   0.605150  0.671429  0.636569\n",
       "4      Phosphorylation    32     37   0.837838  0.968750  0.898551\n",
       "5  Positive_regulation   570    614   0.627036  0.675439  0.650338\n",
       "6   Protein_catabolism    21     26   0.730769  0.904762  0.808511\n",
       "7           Regulation   188    185   0.562162  0.553191  0.557641\n",
       "8        Transcription   112    105   0.647619  0.607143  0.626728\n",
       "9                [All]  1761   1864   0.660944  0.699602  0.679724"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This line calls your function to produce labels for the test set\n",
    "event_dev_guess = predict_event_labels([x for x,_ in event_dev[:]])\n",
    "# This line produces a confusion matrix\n",
    "cm_dev = bio.create_confusion_matrix(event_dev,event_dev_guess)  \n",
    "# This line turns the confusion matrix into a evaluation table with Precision, Recall and F1 for all labels.\n",
    "bio.full_evaluation_table(cm_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to inspect [bio.py](/edit/statnlpbook/bio.py) to see how we define precision, recall and F1 score in this context.\n",
    "\n",
    "You can also display a confusion matrix to identify what types of errors you are currently making. Notice that the matrix ignores the \"None\"-\"None\" cell as its counts would overpower all other counts (try removing the `outside_label` argument). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAEYCAYAAAA+mm/EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nogrJQSYSiUQV/j9BkTk7vHP82gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb4ca4b2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statnlpbook.util as util\n",
    "util.plot_confusion_matrix_dict(cm_dev,90, outside_label=\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix can give you hints on what type of errors you should look for and improve upon. This macro view on your model's performance is often more powerful when combined with a micro view on the instances that produce these errors. You can find errors of a specific type using `bio.find_errors` as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<statnlpbook.bio.EventCandidate at 0x7fbb13d360b8>, 'Transcription', 'None'),\n",
       " (<statnlpbook.bio.EventCandidate at 0x7fbb11102f28>, 'Transcription', 'None'),\n",
       " (<statnlpbook.bio.EventCandidate at 0x7fbb10af55c0>, 'Transcription', 'None')]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = bio.find_errors(\"Transcription\",\"None\", event_dev, event_dev_guess)[:3]\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These errors you can then inspect in detail via `show_event_error`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Gold</th>\n",
       "      <th>Guess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Transcription</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>The <font color='red'>[</font><font color='blue'>[LAZ3]</font><font color='red'>]</font> <font color='red'>[</font><font color='blue'>[/BCL6]</font><font color='red'>]</font> <font color='red'>[</font>transcript<font color='red'>]</font> was <font color='green'>found</font> in a variety <font color='red'>[</font>of<font color='red'>]</font> tissues , <font color='red'>[</font>including<font color='red'>]</font> skeletal muscle , peripheral blood leukocytes , and <font color='red'>[</font>weakly<font color='red'>]</font> in normal lymph nodes .\n",
       "    <div id='displacy35' style=\"overflow: scroll; width: 5000px;\"></div>\n",
       "    <script>\n",
       "    $(function() {\n",
       "    requirejs.config({\n",
       "        paths: {\n",
       "            'displaCy': ['/files/node_modules/displacy/displacy'],\n",
       "                                                  // strip .js ^, require adds it back\n",
       "        },\n",
       "    });\n",
       "    require(['displaCy'], function() {\n",
       "        console.log(\"Loaded :)\");\n",
       "        const displacy = new displaCy('http://localhost:8000', {\n",
       "            container: '#displacy35',\n",
       "            format: 'spacy',\n",
       "            distance: 150,\n",
       "            offsetX: 0,\n",
       "            wordSpacing: 20,\n",
       "            arrowSpacing: 3,\n",
       "\n",
       "        });\n",
       "        const parse = {\n",
       "            arcs: [{\"dir\": \"left\", \"start\": 0, \"label\": \"det\", \"end\": 3}, {\"dir\": \"left\", \"start\": 1, \"label\": \"nn\", \"end\": 3}, {\"dir\": \"left\", \"start\": 2, \"label\": \"nn\", \"end\": 3}, {\"dir\": \"left\", \"start\": 3, \"label\": \"nsubjpass\", \"end\": 5}, {\"dir\": \"left\", \"start\": 4, \"label\": \"auxpass\", \"end\": 5}, {\"dir\": \"left\", \"start\": 7, \"label\": \"det\", \"end\": 8}, {\"dir\": \"right\", \"start\": 5, \"label\": \"prep_in\", \"end\": 8}, {\"dir\": \"right\", \"start\": 8, \"label\": \"prep_of\", \"end\": 10}, {\"dir\": \"left\", \"start\": 13, \"label\": \"amod\", \"end\": 14}, {\"dir\": \"right\", \"start\": 10, \"label\": \"prep_including\", \"end\": 14}, {\"dir\": \"left\", \"start\": 16, \"label\": \"amod\", \"end\": 18}, {\"dir\": \"left\", \"start\": 17, \"label\": \"nn\", \"end\": 18}, {\"dir\": \"right\", \"start\": 14, \"label\": \"appos\", \"end\": 18}, {\"dir\": \"right\", \"start\": 10, \"label\": \"prep_including\", \"end\": 21}, {\"dir\": \"right\", \"start\": 14, \"label\": \"conj_and\", \"end\": 21}, {\"dir\": \"left\", \"start\": 23, \"label\": \"amod\", \"end\": 25}, {\"dir\": \"left\", \"start\": 24, \"label\": \"nn\", \"end\": 25}, {\"dir\": \"right\", \"start\": 21, \"label\": \"prep_in\", \"end\": 25}],\n",
       "            words: [{\"text\": \"The\", \"tag\": \"DT\"}, {\"text\": \"LAZ3\", \"tag\": \"NN\"}, {\"text\": \"/BCL6\", \"tag\": \"NN\"}, {\"text\": \"transcript\", \"tag\": \"NN\"}, {\"text\": \"was\", \"tag\": \"VBD\"}, {\"text\": \"found\", \"tag\": \"VBN\"}, {\"text\": \"in\", \"tag\": \"IN\"}, {\"text\": \"a\", \"tag\": \"DT\"}, {\"text\": \"variety\", \"tag\": \"NN\"}, {\"text\": \"of\", \"tag\": \"IN\"}, {\"text\": \"tissues\", \"tag\": \"NNS\"}, {\"text\": \",\", \"tag\": \",\"}, {\"text\": \"including\", \"tag\": \"VBG\"}, {\"text\": \"skeletal\", \"tag\": \"JJ\"}, {\"text\": \"muscle\", \"tag\": \"NN\"}, {\"text\": \",\", \"tag\": \",\"}, {\"text\": \"peripheral\", \"tag\": \"JJ\"}, {\"text\": \"blood\", \"tag\": \"NN\"}, {\"text\": \"leukocytes\", \"tag\": \"NNS\"}, {\"text\": \",\", \"tag\": \",\"}, {\"text\": \"and\", \"tag\": \"CC\"}, {\"text\": \"weakly\", \"tag\": \"RB\"}, {\"text\": \"in\", \"tag\": \"IN\"}, {\"text\": \"normal\", \"tag\": \"JJ\"}, {\"text\": \"lymph\", \"tag\": \"NN\"}, {\"text\": \"nodes\", \"tag\": \"NNS\"}, {\"text\": \".\", \"tag\": \".\"}]\n",
       "        };\n",
       "\n",
       "        displacy.render(parse, {\n",
       "            uniqueId: 'render_displacy35'\n",
       "            //color: '#ff0000'\n",
       "        });\n",
       "        return {};\n",
       "    });\n",
       "    });\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio.show_event_error(*errors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also be very useful to inspect your feature map for the given instance. Sometimes this leads you to find out that you have a bug in your feature calculation, or that the feature representation is still insufficient for other reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'Child: auxpass->was': 1.0,\n",
       "             'Child: nsubjpass->transcript': 1.0,\n",
       "             'Child: prep_in->variety': 1.0,\n",
       "             'GrandChild: det->The': 1.0,\n",
       "             'GrandChild: det->a': 1.0,\n",
       "             'GrandChild: nn->/BCL6': 1.0,\n",
       "             'GrandChild: nn->LAZ3': 1.0,\n",
       "             'GrandChild: prep_of->tissues': 1.0,\n",
       "             'No protein lies nearfound': 2.0,\n",
       "             'Number of Proteins=2': 1.0,\n",
       "             \"Protein's parent is not a trigger:nn\": 2.0,\n",
       "             'beside trigger is INfoundin': 1.0,\n",
       "             'beside trigger is not INfoundwas': 1.0,\n",
       "             'minimum distance between protein and trigger = inf': 1.0,\n",
       "             'trigger is not INfound': 1.0,\n",
       "             'trigger_word=VBN': 1.0,\n",
       "             'trigger_word=found': 2.0})"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_feat(errors[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 2</font>: Assess Accuracy (50+10 pts) \n",
    "\n",
    "We assess how well your model performs on some unseen test set. We will look at the F1 across all event types, and will score them as follows:\n",
    "\n",
    "* 0-40pts: 17% <= F1 < 60%, linear\n",
    "* 40-50pts: 60% <= F1 < 70%, linear\n",
    "* 50-60pts: 70% <= F1 < 80%, linear\n",
    "\n",
    "The **linear** mapping maps any F1 value between the lower and upper bound linearly to a score. For example, if your model's F1 score is $F=55$, then your score is $40\\frac{F-17}{60-17}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6797241379310344"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! ASSESSMENT 2 - DO NOT CHANGE, MOVE NOR COPY\n",
    "_snlp_event_test = event_dev # This line will be changed by us after submission to point to a test set.\n",
    "_snlp_event_test_guess = predict_event_labels([x for x,_ in _snlp_event_test[:]])\n",
    "_snlp_cm_test = bio.create_confusion_matrix(_snlp_event_test,_snlp_event_test_guess)  \n",
    "bio.evaluate(_snlp_cm_test)[2] # This is the F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Mark</font>:  Your solution to Task 2 is marked with ** __ points**. \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 3</font>: Describe your Approach\n",
    "\n",
    "Enter a 500 words max description of your approach **in this cell**. Also provide an **error analysis** of the types of errors your system still makes, with suggestions on how to improve it further. Should you need to include figures in your report, make sure they are Python-generated. For that, feel free to create new cells after this cell (before Assessment 3 cell). Link online images at your risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 3</font>: Assess Description (30 pts) \n",
    "\n",
    "We will mark the description along the following dimensions: \n",
    "\n",
    "* Clarity (10pts: very clear, 0pts: we can't figure out what you did)\n",
    "* Creativity (10pts: we could not have come up with this, 0pts: Use only word based features of the trigger word)\n",
    "* Substance (10pts: implemented complex state-of-the-art classifier, 0pts: Only use what is already there)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset data structure\n",
    "\n",
    "The \"event_candidate\" object consists of a sentence \"sent\", the position \"trigger_index\" of the trigger candidate word and the true arguments of the events \"argument_candidate_spans\". Specifically, the \"sent\" object has several useful features — \"mentions\", \"tokens\", \"dependencies\", \"parents\", \"children\", and \"is_protein\".  The \"label\" is one of the elements in a set includes 10 labels.\n",
    "\n",
    "To convince the training, the event candidates and the corresponding labels are converted into vectors and integers. The resulted \"train_event_x\" is a sparse matrix with size [53988 x m], where m depends on the features added in the function \"event_feat\".\n",
    "\n",
    "### Feature extracted\n",
    "\n",
    "- I tried to use TF-IDF algorithm to get the importance of the words in the corpus by finding the \"word frequency\". However, the effect is not that much remarkable. The possible reason is that sometimes the word appears less frequent is of greater importance.\n",
    "- Trigger word, in this case, is an important feature, therefore I first extracted several tokens of the trigger word,  \"word\", \"stem\", \"pos\". \n",
    "- Based on Task1, the \"grandchild\" and \"grandparent\" was further added as a feature. \n",
    "- It was accidentally found that the number of proteins in a sentence (the length of \"sent.mentions\") can be a quite good feature.\n",
    "- Trigger words have a close connection with proteins, from the output of \"render_dependencies\", the label of protein's parent/child varies a lot, there are several features extracted based on this. \n",
    "  - the label from a protein to its child/parent\n",
    "  - the minimum distance between protein and trigger word\n",
    "  - whether the trigger word has protein besides\n",
    "    What is worth mentioning is that here \"stem\" has the better performance here. In the case of protein with more than one word, I employed a for loop to map through the whole protein.\n",
    "- Moving to the \"pos\" objective of words, trigger words of sentence labelled by \"None\" is \"IN\" and those not labelled by \"None\" is usually in beside of \"IN\" word in common. Therefore the trigger word and the word beside it together can be a feature. \n",
    "\n",
    "### Classifier Implementation\n",
    "\n",
    "To find appropriate regularization strength for the logistic-regression, \"cross_validation\" was employed( presented in Raw NBConvert). It was found that when C = 2, the f-1 score reached the highest. Moreover, the class_weight was set to be \"balanced\", this mode uses the values of y to automatically adjust weights.\n",
    "\n",
    "I also tried several other classifiers, like RandomForest, Gradient boosting and SVM. Comparing with Logistic regression, their performance still cannot have any breakthroughs.\n",
    "\n",
    "### Error analysis\n",
    "\n",
    "From the plotted confusion matrix, most of the mispredictions happen to the sentences originally and predictably labelled by \"None\", these sentences' weight should be spread to the diagonal blocks of the confusion matrix.  Further improvements can be achieved by adding more training data for extracting more features. Also, more classifiers can be attempted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Mark</font>:  Your solution to Task 3 is marked with ** __ points**.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Final mark</font>: Your solution to Assignment 2 is marked with ** __points**. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
