{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment you will build a language model for the [OHHLA corpus](http://ohhla.com/) we are using in the book. You will train the model on the available training set, and can tune it on the development set. After submission we will run your notebook on a different test set. Your mark will depend on \n",
    "\n",
    "* whether your language model is **properly normalized**,\n",
    "* its **perplexity** on the unseen test set,\n",
    "* your **description** of your approach. \n",
    "\n",
    "To develop your model you have access to:\n",
    "\n",
    "* The training and development data in `data/ohhla`.\n",
    "* The code of the lecture, stored in a python module [here](/edit/statnlpbook/lm.py).\n",
    "* Libraries on the [docker image](https://github.com/uclmr/stat-nlp-book/blob/python/Dockerfile) which contains everything in [this image](https://github.com/jupyter/docker-stacks/tree/master/scipy-notebook), including scikit-learn and tensorflow. \n",
    "\n",
    "As we have to run the notebooks of all students, and because writing efficient code is important, **your notebook should run in 5 minutes at most**, on your machine. Further comments:\n",
    "\n",
    "* We have tested a possible solution on the Azure VMs and it ran in seconds, so it is possible to train a reasonable LM on the data in reasonable time. \n",
    "\n",
    "* Try to run your parameter optimisation offline, such that in your answer notebook the best parameters are already set and don't need to be searched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Instructions\n",
    "It is important that this file is placed in the **correct directory**. It will not run otherwise. The correct directory is\n",
    "\n",
    "    DIRECTORY_OF_YOUR_BOOK/assignments/2017/assignment1/problem/\n",
    "    \n",
    "where `DIRECTORY_OF_YOUR_BOOK` is a placeholder for the directory you downloaded the book to. After you placed it there, **rename the file** to your UCL ID (of the form `ucxxxxx`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Instructions\n",
    "This notebook will be used by you to provide your solution, and by us to both assess your solution and enter your marks. It contains three types of sections:\n",
    "\n",
    "1. **Setup** Sections: these sections set up code and resources for assessment. **Do not edit these**. \n",
    "2. **Assessment** Sections: these sections are used for both evaluating the output of your code, and for markers to enter their marks. **Do not edit these**. \n",
    "3. **Task** Sections: these sections require your solutions. They may contain stub code, and you are expected to edit this code. For free text answers simply edit the markdown field.  \n",
    "\n",
    "Note that you are free to **create additional notebook cells** within a task section. \n",
    "\n",
    "Please **do not share** this assignment publicly, by uploading it online, emailing it to friends etc. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "To submit your solution:\n",
    "\n",
    "* Make sure that your solution is fully contained in this notebook. \n",
    "* **Rename this notebook to your UCL ID** (of the form \"ucxxxxx\"), if you have not already done so.\n",
    "* Download the notebook in Jupyter via *File -> Download as -> Notebook (.ipynb)*.\n",
    "* Upload the notebook to the Moodle submission site.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 1</font>: Load Libraries\n",
    "This cell loads libraries important for evaluation and assessment of your model. **Do not change it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! SETUP 1\n",
    "import sys, os\n",
    "_snlp_book_dir = \"../../../../\"\n",
    "sys.path.append(_snlp_book_dir) \n",
    "import statnlpbook.lm as lm\n",
    "import statnlpbook.ohhla as ohhla\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 2</font>: Load Training Data\n",
    "\n",
    "This cell loads the training data. We use this data for assessment to define the reference vocabulary: the union of the words of the training and set set. You can use the dataset to train your model, but you are also free to load the data in a different way, or focus on subsets etc. However, when you do this, still **do not edit this setup section**. Instead refer to the variables in your own code, and slice and dice them as you see fit.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load ../../../..//data/ohhla/train/www.ohhla.com/anonymous/nas/distant/tribal.nas.txt.html\n"
     ]
    }
   ],
   "source": [
    "#! SETUP 2\n",
    "_snlp_train_dir = _snlp_book_dir + \"/data/ohhla/train\"\n",
    "_snlp_dev_dir = _snlp_book_dir + \"/data/ohhla/dev\"\n",
    "_snlp_train_song_words = ohhla.words(ohhla.load_all_songs(_snlp_train_dir))\n",
    "_snlp_dev_song_words = ohhla.words(ohhla.load_all_songs(_snlp_dev_dir))\n",
    "assert(len(_snlp_train_song_words)==1041496)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to file encoding issues this code produces one error `Could not load ...`. **Ignore this error**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 1</font>: Develop and Train the Model\n",
    "\n",
    "This is the core part of the assignment. You are to code up, train and tune a language model. Your language model needs to be subclass of the `lm.LanguageModel` class. You can use some of the existing language models developed in the lecture, or develop your own extensions. \n",
    "\n",
    "Concretely, you need to return a better language model in the `create_lm` function. This function receives a target vocabulary `vocab`, and it needs to return a language model defined over this vocabulary. \n",
    "\n",
    "The target vocab will be the union of the training and test set (hidden to you at development time). This vocab will contain words not in the training set. One way to address this issue is to use the `lm.OOVAwareLM` class discussed in the lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inject OOVs into the training dataset \n",
    "oov_train = lm.inject_OOVs(_snlp_train_song_words)\n",
    "oov_dev = lm.inject_OOVs(_snlp_dev_song_words)\n",
    "#len(oov_train)---1041496\n",
    "#len(oov_vocab)   --- 20460\n",
    "\n",
    "#The sets module provides classes for constructing and manipulating unordered collections of unique elements.\n",
    "#so here oov_vocab provides a set of unique elements in oov_train, which can be treated as a vocabulary list\n",
    "oov_vocab = set(oov_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color='orange'>Smoothing algorithms</font>      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statnlpbook.lm import *\n",
    "## StupidBackoffNormalized function can fix the normalization problem of the StupidBackoff function            \n",
    "class StupidBackoffNormalized(LanguageModel):\n",
    "    def __init__(self, main, backoff, alpha):\n",
    "        super().__init__(main.vocab, main.order)\n",
    "        self.main = main\n",
    "        self.backoff = backoff\n",
    "        self.alpha = alpha               \n",
    "\n",
    "    def probability(self, word, *history):\n",
    "        main_counts = self.main.counts((word,)+tuple(history))\n",
    "        main_norm = self.main.norm(history)        \n",
    "        backoff_order_diff = self.main.order - self.backoff.order\n",
    "        backoff_counts = self.backoff.counts((word,)+tuple(history[:-backoff_order_diff]))\n",
    "        backoff_norm = self.backoff.norm(history[:-backoff_order_diff])        \n",
    "        counts = main_counts + self.alpha * backoff_counts\n",
    "        norm = main_norm + self.alpha * backoff_norm\n",
    "        return counts / norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <font color='orange'>Interpolation Smoothing</font>     \n",
    "Based on the given'InterpolatedLM' function, I combining and weighing the trigram, bigram, and unigram counts. This can be represented by following function:\n",
    "\n",
    "\n",
    "$$\n",
    "P(w_n|w_{n-2}w_{n-1})=\\lambda_1(w_{n-2}^{n-1})P(w_n|w_{n-2}w_{n-1})+\\lambda_2(w_{n-2}^{n-1})P(w_n|w_{n-1})+\\lambda_3(w_{n-2}^{n-1})P(w)\\\\\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#interplotedLM2 function takes two backoffs, which given similar effect as using InterplotedLM twice\n",
    "class InterpolatedLM2(LanguageModel):\n",
    "    def __init__(self, main, backoff1,backoff2, alpha1, alpha2):\n",
    "        super().__init__(main.vocab, main.order)\n",
    "        self.main = main\n",
    "        self.backoff1 = backoff1\n",
    "        self.backoff2 = backoff2\n",
    "        self.alpha1 = alpha1\n",
    "        self.alpha2 = alpha2\n",
    "\n",
    "    def probability(self, word, *history):\n",
    "        return self.alpha1 * self.main.probability(word, *history) + \\\n",
    "                self.alpha2 * self.backoff1.probability(word, *history) + \\\n",
    "               (1.0 - self.alpha1 - self.alpha2) * self.backoff2.probability(word, *history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <font color='orange'>Kneser-Ney Smoothing</font>  \n",
    "For given size of the training dataset, Kneser-Ney Smoothing is supposed to give good performance. Consider the simplification of Kneser-Net Smoothing -- Absolute Discounting. It is similar to interpolation, however, Absolute Discouting Algorithm subtracts a fixed discount $$\\delta \\in [0,1]$$ \n",
    "\n",
    "$$\n",
    "P_{\\mbox{Absolute}}(w|h_{m}) = \n",
    "\\begin{cases}\n",
    "\\frac {\\#_D(h_{m},w)}{\\#_D(h_{m})} -d  &= \\mbox{if }\\#_D{h_{m},w} > 0 \\\\\\\\\n",
    "\\alpha(h_{m-1})\\cdot P_{\\mbox{Absolute}}(w|h_{m-1}) & \\mbox{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$\\alpha(h_{m-1})$ is a normalizer\n",
    "\n",
    "$$\\alpha(h_{m-1})=\\frac{d}{\\sum_{w^{'}} c(w_{i-1},w^{'})} | {w^{'}:0 < c(w_{i-1},w^{'})} |\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AbsoultDiscounting(LanguageModel):\n",
    "    def __init__(self, main, backoff, d):\n",
    "        super().__init__(main.vocab, main.order)\n",
    "        self.main = main\n",
    "        self.backoff = backoff\n",
    "        self.d = d\n",
    "\n",
    "    def probability(self, word, *history):\n",
    "        main_counts = self.main.counts((word,)+tuple(history))\n",
    "        main_norm = self.main.norm(history)        \n",
    "        backoff_counts = self.backoff.counts((word,)+tuple(history[1:]))\n",
    "        backoff_norm = self.backoff.norm(history[:-backoff_order_diff])\n",
    "        norm = main_norm + self.alpha * backoff_norm\n",
    "        #lambda = d/ (w_{i-1}: w_{i-1} w_i) \n",
    "        if norm == 0:\n",
    "            return self.backoff.probability(word, *history)\n",
    "        else:\n",
    "            return (main_counts - self.d)/backoff_counts + alpha * self.backoff.probability(word, *history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <font color='orange'>Katz Smoothing</font>  \n",
    "Katz Smoothing applies Good Turning estimates to the problem of backoff language models. It uses a form of discounting, the total number of counts discounted in the global distribution is equal to the total number of counts that should be assigned to N-Grams with zero counts according to Good Turning estimate.\n",
    "\n",
    "$$\n",
    "P_{\\mbox{Katz}}(w_i|w_{i-1})=\n",
    "\\begin{cases}\n",
    "\\frac{C(w_{i-1}w_i)}{C(W_{i-1})}  &\\mbox{r>k}\\\\\\\\\n",
    "d_r\\frac{C(w_{i-1}w_i)}{C(W_{i-1})}&\\mbox{ k>=r>0}\\\\\\\\\n",
    "\\alpha (w_{i-1})P(w_i)&\\mbox{r=0}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where \n",
    "$$\n",
    "r^*=(r+1)\\frac{n_{r+1}}{n_r}\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_r=\\frac{\\frac{r^*}{r}-\\frac{(k+1)n_{k+1}}{n_1}}{1-\\frac{(k+1)n_{k+1}}{n_1}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\alpha(w_{i-1})=\\frac{1-\\sum_{w_i:r>0}P_{Katz}(w_i|w_{i-1})}{1-\\sum_{w_i:r>0}P_{Katz}(w_i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KatzSmoothing(LanguageModel):\n",
    "    def __init__(self, main, backoff,k):\n",
    "        super().__init__(main.vocab, main.order)\n",
    "        self.main = main\n",
    "        self.backoff = backoff\n",
    "        self.k = k\n",
    "\n",
    "    def probability(self, word, *history):\n",
    "        r = counts[word]\n",
    "        if (r > 0 and r <= self.k):\n",
    "            \n",
    "            r_star = (r+1) * (sorted_counts[r+1]/sorted_counts[r])\n",
    "            dr = ((r_star/r) - ((self.k + 1) * sorted_counts[self.k + 1] / sorted_counts[1])) / \\\n",
    "                (1 - ((self.k+1) * sorted_counts[self.k + 1] / (sorted_counts[1])))\n",
    "            return dr * self.backoff.counts((word,)+tuple(history[:-1])) / r \n",
    "        elif (r > self.k):\n",
    "            return self.backoff.counts((word,)+tuple(history[:-1])) / r\n",
    "        else:\n",
    "            return (1 - np.sum(self.main.probability(word, *history))) / (1 - np.sum(self.backoff.probability(word, *history)))\n",
    "       "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_snlp_test_dir = _snlp_book_dir + \"/data/ohhla/dev\"\n",
    "_snlp_test_song_words = ohhla.words(ohhla.load_all_songs(_snlp_test_dir))\n",
    "_snlp_test_vocab = set(_snlp_test_song_words)\n",
    "_snlp_dev_vocab = set(_snlp_dev_song_words)\n",
    "_snlp_train_vocab = set(_snlp_train_song_words)\n",
    "_snlp_vocab = _snlp_test_vocab | _snlp_train_vocab | _snlp_dev_vocab"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "unigram = lm.LaplaceLM(lm.NGramLM(oov_train, 1),0.4)\n",
    "bigram = lm.NGramLM(oov_train, 2)\n",
    "trigram = lm.NGramLM(oov_train, 3)\n",
    "quadgram = lm.NGramLM(oov_train, 4)\n",
    "pentagram = lm.NGramLM(oov_train, 5)\n",
    "for alpha1 in np.arange(0.7,0.75,0.01):\n",
    "    my_LM1=lm.InterpolatedLM(bigram,unigram,alpha1)\n",
    "    for alpha2 in np.arange(0.2,0.4,0.01):\n",
    "        my_LM2=lm.InterpolatedLM(trigram,my_LM1,alpha2)\n",
    "        for alpha3 in np.arange(0,0.4,0.1):\n",
    "            my_LM3=lm.InterpolatedLM(quadgram,my_LM2,alpha3)\n",
    "            for alpha4 in np.arange(0,0.4,0.1):\n",
    "                my_LM=lm.InterpolatedLM(pentagram,my_LM3,alpha4)\n",
    "                _snlp_lm = lm.OOVAwareLM(my_LM, _snlp_vocab - oov_vocab)\n",
    "                print(alpha1,alpha2,alpha3,alpha4,lm.perplexity(_snlp_lm, _snlp_test_song_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## You should improve this cell\n",
    "def create_lm(vocab):\n",
    "    \"\"\"\n",
    "    Return an instance of `lm.LanguageModel` defined over the given vocabulary.\n",
    "    Args:\n",
    "        vocab: the vocabulary the LM should be defined over. It is the union of the training and test words.\n",
    "    Returns:\n",
    "        a language model, instance of `lm.LanguageModel`.\n",
    "    \"\"\"\n",
    "\n",
    "    unigram = lm.LaplaceLM(lm.NGramLM(oov_train, 1),0.4)\n",
    "    bigram = lm.NGramLM(oov_train, 2)\n",
    "    trigram = lm.NGramLM(oov_train, 3)\n",
    "    quadgram = lm.NGramLM(oov_train, 4)\n",
    "    pentagram = lm.NGramLM(oov_train, 5)\n",
    "    sixgram = lm.NGramLM(oov_train, 6)\n",
    "    my_LM1=lm.InterpolatedLM(bigram,unigram,0.7)        \n",
    "    my_LM2=lm.InterpolatedLM(trigram,my_LM1,0.17)\n",
    "    my_LM3=lm.InterpolatedLM(quadgram,my_LM2,0.02)\n",
    "    my_LM4=lm.InterpolatedLM(pentagram,my_LM3,0.04)\n",
    "    my_LM=lm.InterpolatedLM(sixgram,my_LM4,0.05)\n",
    "  \n",
    "    # the unseen words can be achieved by subtract vocab with oov_vocab\n",
    "    return lm.OOVAwareLM(my_LM, vocab - oov_vocab)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 3</font>: Specify Test Data\n",
    "This cell defines the directory to load the test songs from. Currently, this points to the dev set but when we evaluate your notebook we will point this directory elsewhere and use a **hidden test set**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! SETUP 3\n",
    "_snlp_test_dir = _snlp_book_dir + \"/data/ohhla/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 4</font>: Load Test Data and Prepare Language Model\n",
    "In this section we load the test data, prepare the reference vocabulary and then create your language model based on this vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../..//data/ohhla/test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b595f5e79d39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#! SETUP 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0m_snlp_test_song_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mohhla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mohhla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_all_songs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_snlp_test_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0m_snlp_test_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_snlp_test_song_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m_snlp_dev_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_snlp_dev_song_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_snlp_train_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_snlp_train_song_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ucl-DSML/Github/NLP/stat-nlp-book/statnlpbook/ohhla.py\u001b[0m in \u001b[0;36mload_all_songs\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_all_songs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0monly_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'txt'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0monly_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mlyrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mload_song\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0monly_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../..//data/ohhla/test'"
     ]
    }
   ],
   "source": [
    "#! SETUP 4\n",
    "_snlp_test_song_words = ohhla.words(ohhla.load_all_songs(_snlp_test_dir))\n",
    "_snlp_test_vocab = set(_snlp_test_song_words)\n",
    "_snlp_dev_vocab = set(_snlp_dev_song_words)\n",
    "_snlp_train_vocab = set(_snlp_train_song_words)\n",
    "_snlp_vocab = _snlp_test_vocab | _snlp_train_vocab | _snlp_dev_vocab\n",
    "_snlp_lm = create_lm(_snlp_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 1</font>: Test Normalization (20 pts)\n",
    "Here we test whether the conditional distributions of your language model are properly normalized. If probabilities sum up to $1$ you get full points, you get half of the points if probabilities sum up to be smaller than 1, and 0 points otherwise. Due to floating point issues we will test with respect to a tolerance $\\epsilon$ (`_eps`).\n",
    "\n",
    "Points:\n",
    "* 10 pts: $\\leq 1 + \\epsilon$\n",
    "* 20 pts: $\\approx 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#! ASSESSMENT 1\n",
    "_snlp_test_token_indices = [100, 1000, 10000]\n",
    "_eps = 0.000001\n",
    "approx_1 = []\n",
    "leq_1 = []\n",
    "for i in _snlp_test_token_indices:\n",
    "    result = sum([_snlp_lm.probability(word, *_snlp_test_song_words[i-_snlp_lm.order+1:i]) for word in _snlp_vocab])\n",
    "    approx_1.append(abs(result - 1.0) < _eps)\n",
    "    leq_1.append(result - _eps <= 1.0)\n",
    "    \n",
    "    print(\"Sum: {sum}, ~1: {approx_1}, <=1: {leq_1}\".format(sum=result, \n",
    "                                                            approx_1=abs(result - 1.0) < _eps, \n",
    "                                                            leq_1=result - _eps <= 1.0))\n",
    "(sum(approx_1) == 3, sum(leq_1) == 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above solution is marked with **\n",
    "<!-- ASSESSMENT 2: START_POINTS -->\n",
    "20\n",
    "<!-- ASSESSMENT 2: END_POINTS --> \n",
    "points **."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Assessment 2</font>: Apply to Test Data (50 pts)\n",
    "\n",
    "We assess how well your LM performs on some unseen test set. Perplexities are mapped to points as follows.\n",
    "\n",
    "* 0-10 pts: uniform perplexity > perplexity > 550, linear\n",
    "* 10-30 pts: 550 > perplexity > 140, linear\n",
    "* 30-50 pts: 140 > perplexity > 105, linear\n",
    "\n",
    "The **linear** mapping maps any perplexity value between the lower and upper bound linearly to a score. For example, if uniform perplexity is $U$ and your model's perplexity is $P\\leq550$, then your score is $10\\frac{P-U}{550-U}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.perplexity(_snlp_lm, _snlp_test_song_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above solution is marked with **\n",
    "<!-- ASSESSMENT 3: START_POINTS -->\n",
    "29\n",
    "<!-- ASSESSMENT 3: END_POINTS --> points**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 2</font>: Describe your Approach\n",
    "\n",
    "< Enter a 500 words max description of your model and the way you trained and tuned it here >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 3</font>: Assess Description (30 pts) \n",
    "\n",
    "We will mark the description along the following dimensions: \n",
    "\n",
    "* Clarity (10pts: very clear, 0pts: we can't figure out what you did)\n",
    "* Creativity (10pts: we could not have come up with this, 0pts: Use the unigram model from the lecture notes)\n",
    "* Substance (10pts: implemented complex state-of-the-art LM, 0pts: Use the unigram model from the lecture notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Clarity: 10\n",
    "* Creativity: 4 (2 for interpolated n-grams, 2 for extra methods thought of (katz, kn)\n",
    "* Substance: 4 (same as creativity)\n",
    "\n",
    "The above solution is marked with **\n",
    "<!-- ASSESSMENT 1: START_POINTS -->\n",
    "18\n",
    "<!-- ASSESSMENT 1: END_POINTS --> points**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Pretreatment of training data</font>\n",
    "I first use the 'inject_OOV' function, which use a heuristic to inject OOV symbols into a dataset. Here, the first appearance of a word in 'oov_train' will be treated as 'unknow words', being labeled as OOV.\n",
    "\n",
    "Given new sequence of training data with OOV injected. 'oov_vocab' provides a set of unique elements in 'oov_train', this can be treated as a vocabulary list.\n",
    "\n",
    "'OOVAvareLM'is used to return a language model in 'create_lm'. Given input argument 'vacab', 'vocab - oov_vocab' represents the words that are included in 'vocab' while not in 'oov_vocab'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>N-Grams and Add-k Smoothing</font> \n",
    "For the given training data('oov_train'), the perplexity of either unigram,bigram or trigram are 'inf'. Therefore, I first applied 'lm.LaplaceLM' function (Add-k smoothing) to improve the language model.\n",
    "\n",
    "By using the 'for loop', the optimal fractional count alpha was found. (with alpha = 0.4,perplexity_unigram = 547.5497189073692; With alpha = 0.004,  perplexity_bigram =300.97971886348046). Which is worth mentioning is that,even with optimal alpha, the perplexity of trigram is much larger than bigram. Thereby, bigram performs best with the given data.\n",
    "\n",
    "###  <font color='orange'>Improvement on Backoff and Interpolation </font>  \n",
    "\n",
    "Backoff and Interpolation both use kind of N-Gram 'Hierarchy'. In back-off, we only 'back-off' to lower-order n-Gram if we have zero evidence for a higher-order n-Gram. While in Interpolation, we mixed the probability estimations from all the n-Gram estimators.\n",
    "\n",
    "The given 'StupidBackoff' is lack of normalization while the 'StupidBackoffNormalized' fixed this problem and gives perplexity improved to '239.9377346450501'. And 'InterpolatedLM' shows better performance with perplexity '188.57971535126373'. Based on the given 'InterpolatedLM', which linearly interpolated a bigram with a unigram.  'InterpolatedLM2' that combines trigram, bigram and unigram, the perplexity, given optimal lambdas is '164.220977639824'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color='orange'>work done so far for other Smoothing Methods</font>  \n",
    "The perplexity turns out to be inf when the Katz Smoothing algorithm is applied to the n-Grams.\n",
    "\n",
    "    This might due to following issues when applying Good Turing:\n",
    "\n",
    "    The adjusted count r* might equal to zero if the number of n-grams seen r+1 times {n_(r+1)} equals to zero, which leads to the holes in the counts of counts. Also, n_r are quite noisy for high r. \n",
    "\n",
    "    Thereby, it should be better think of \n",
    "$$\n",
    "r^*=(r+1)\\frac{E[n_{r+1}]}{E[n_r]}\n",
    "$$\n",
    "\n",
    "    rather than\n",
    "$$\n",
    "r^*=(r+1)\\frac{n_{r+1}}{n_r}\n",
    "$$\n",
    "\n",
    "To estimate the expectation, ML estimate can be used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color='orange'>Find optimal parameters for language model</font>  \n",
    "\n",
    "I used \"nested for loop\" to find an optimal parameters for the chosen language model. \n",
    "Firstly, the parameters are set with range(0,1,0.1), a rough range of target alpha can be achieved from this step. The range can thereby be reduced around the parameter sets with smallest perplexity, and the steps can be minished. For complex models, small changes in parameters can cause big changes in the result.\n",
    "\n",
    "For a single n-gram, the optimization is simple that we just need one loop.\n",
    "\n",
    "Considering Laplace Smoothing, it turns out that it cannot make much enhancement for this task; therefore, I just used 'LaplaceLM' for unigram.\n",
    "\n",
    "Speaking of Interpolation Smoothing. When a bigram is linearly interpolated with a unigram, the discounting rate is found to be around '0.7167', given perplexity of '188.57971535126373'.\n",
    "In order to estimate the trigram probability by mixing together the unigram, bigram and trigram probabilities, each weighted by a $\\lambda $(the sum of this three lambda is 1), I wrote a simple 'InterpolatedLM2' class. The optimal $\\lambda$ for trigram, bigram and unigram are '0.22'，‘0.52’ and '0.28' respectively. Given perplexity of '164.220977639824'.\n",
    "Based on this, I tried to use both 'InterpolatedLM' and 'InterpolatedLM2' to see how it performs. The optimal $\\lambda$ for quadgram, trigram, bigram and unigram are '0.1','0.1','0.1' and '0.7' respectively. Given perplexity of '156.12951366236243'. However, during the tuning it reflected that the perplexity was infinite with some parameter sets.\n",
    "Therefore, I chose to use the given 'InterpolatedLM' for my final language model. The function was called for five times to mixed the estimator of 1-Gram to 6-Gram. And the final perplexity is '151.263077651845'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
