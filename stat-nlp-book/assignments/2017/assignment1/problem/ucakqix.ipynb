{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment you will build a language model for the [OHHLA corpus](http://ohhla.com/) we are using in the book. You will train the model on the available training set, and can tune it on the development set. After submission we will run your notebook on a different test set. Your mark will depend on \n",
    "\n",
    "* whether your language model is **properly normalized**,\n",
    "* its **perplexity** on the unseen test set,\n",
    "* your **description** of your approach. \n",
    "\n",
    "To develop your model you have access to:\n",
    "\n",
    "* The training and development data in `data/ohhla`.\n",
    "* The code of the lecture, stored in a python module [here](/edit/statnlpbook/lm.py).\n",
    "* Libraries on the [docker image](https://github.com/uclmr/stat-nlp-book/blob/python/Dockerfile) which contains everything in [this image](https://github.com/jupyter/docker-stacks/tree/master/scipy-notebook), including scikit-learn and tensorflow. \n",
    "\n",
    "As we have to run the notebooks of all students, and because writing efficient code is important, **your notebook should run in 5 minutes at most**, on your machine. Further comments:\n",
    "\n",
    "* We have tested a possible solution on the Azure VMs and it ran in seconds, so it is possible to train a reasonable LM on the data in reasonable time. \n",
    "\n",
    "* Try to run your parameter optimisation offline, such that in your answer notebook the best parameters are already set and don't need to be searched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Instructions\n",
    "It is important that this file is placed in the **correct directory**. It will not run otherwise. The correct directory is\n",
    "\n",
    "    DIRECTORY_OF_YOUR_BOOK/assignments/2017/assignment1/problem/\n",
    "    \n",
    "where `DIRECTORY_OF_YOUR_BOOK` is a placeholder for the directory you downloaded the book to. After you placed it there, **rename the file** to your UCL ID (of the form `ucxxxxx`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Instructions\n",
    "This notebook will be used by you to provide your solution, and by us to both assess your solution and enter your marks. It contains three types of sections:\n",
    "\n",
    "1. **Setup** Sections: these sections set up code and resources for assessment. **Do not edit these**. \n",
    "2. **Assessment** Sections: these sections are used for both evaluating the output of your code, and for markers to enter their marks. **Do not edit these**. \n",
    "3. **Task** Sections: these sections require your solutions. They may contain stub code, and you are expected to edit this code. For free text answers simply edit the markdown field.  \n",
    "\n",
    "Note that you are free to **create additional notebook cells** within a task section. \n",
    "\n",
    "Please **do not share** this assignment publicly, by uploading it online, emailing it to friends etc. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "To submit your solution:\n",
    "\n",
    "* Make sure that your solution is fully contained in this notebook. \n",
    "* **Rename this notebook to your UCL ID** (of the form \"ucxxxxx\"), if you have not already done so.\n",
    "* Download the notebook in Jupyter via *File -> Download as -> Notebook (.ipynb)*.\n",
    "* Upload the notebook to the Moodle submission site.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 1</font>: Load Libraries\n",
    "This cell loads libraries important for evaluation and assessment of your model. **Do not change it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! SETUP 1\n",
    "import sys, os\n",
    "_snlp_book_dir = \"../../../../\"\n",
    "sys.path.append(_snlp_book_dir) \n",
    "import statnlpbook.lm as lm\n",
    "import statnlpbook.ohhla as ohhla\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 2</font>: Load Training Data\n",
    "\n",
    "This cell loads the training data. We use this data for assessment to define the reference vocabulary: the union of the words of the training and set set. You can use the dataset to train your model, but you are also free to load the data in a different way, or focus on subsets etc. However, when you do this, still **do not edit this setup section**. Instead refer to the variables in your own code, and slice and dice them as you see fit.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load ../../../..//data/ohhla/train/www.ohhla.com/anonymous/nas/distant/tribal.nas.txt.html\n"
     ]
    }
   ],
   "source": [
    "#! SETUP 2\n",
    "_snlp_train_dir = _snlp_book_dir + \"/data/ohhla/train\"\n",
    "_snlp_dev_dir = _snlp_book_dir + \"/data/ohhla/dev\"\n",
    "_snlp_train_song_words = ohhla.words(ohhla.load_all_songs(_snlp_train_dir))\n",
    "_snlp_dev_song_words = ohhla.words(ohhla.load_all_songs(_snlp_dev_dir))\n",
    "assert(len(_snlp_train_song_words)==1041496)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to file encoding issues this code produces one error `Could not load ...`. **Ignore this error**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 1</font>: Develop and Train the Model\n",
    "\n",
    "This is the core part of the assignment. You are to code up, train and tune a language model. Your language model needs to be subclass of the `lm.LanguageModel` class. You can use some of the existing language models developed in the lecture, or develop your own extensions. \n",
    "\n",
    "Concretely, you need to return a better language model in the `create_lm` function. This function receives a target vocabulary `vocab`, and it needs to return a language model defined over this vocabulary. \n",
    "\n",
    "The target vocab will be the union of the training and test set (hidden to you at development time). This vocab will contain words not in the training set. One way to address this issue is to use the `lm.OOVAwareLM` class discussed in the lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inject OOVs into training dataset \n",
    "oov_train = lm.inject_OOVs(_snlp_train_song_words)\n",
    "oov_vocab = set(oov_train)\n",
    "#len(oov_def)   ---162479\n",
    "#len(oov_train)   ---1041496\n",
    "#len(oov_vocab)   --- 20460"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33485"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"call\"\n",
    "history = \"this\"\n",
    "bigram.counts((word,)+tuple(history))\n",
    "counts[\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statnlpbook.util as util\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "unigram = lm.LaplaceLM(lm.NGramLM(oov_train, 1),0.04)\n",
    "bigram = lm.LaplaceLM(lm.NGramLM(oov_train, 2),0.04)\n",
    "my_LM1 = lm.InterpolatedLM(bigram,unigram,0.714)\n",
    "trigram = lm.LaplaceLM(lm.NGramLM(oov_train,3),0.04)\n",
    "my_LM = lm.InterpolatedLM(trigram, my_LM1, 0.217)\n",
    "\n",
    "\n",
    "def plot_probabilities(lm, context = (), how_many = 10):    \n",
    "    probs = sorted([(word,lm.probability(word,*context)) for word in lm.vocab], key=lambda x:x[1], reverse=True)[:how_many]\n",
    "    util.plot_bar_graph([prob for _,prob in probs], [word for word, _ in probs])\n",
    "    \n",
    "#plot_probabilities(my_LM,\"the\")\n",
    "lm.sample(bigram,[],10)\n",
    "\n",
    "import collections\n",
    "counts = collections.defaultdict(int)\n",
    "for word in oov_train:\n",
    "    counts[word] += 1\n",
    "sorted_counts = sorted(counts.values(),reverse=True)\n",
    "ranks = range(1,len(sorted_counts)+1)\n",
    "max(sorted_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different language models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "for alpha in np.arange(0,1,0.1):\n",
    "    my_LM = lm.LaplaceLM(lm.NGramLM(oov_train, 1),alpha)\n",
    "    _snlp_lm = create_lm(_snlp_vocab)\n",
    "    print(alpha,lm.perplexity(_snlp_lm, _snlp_test_song_words))\n",
    "    \n",
    "    \n",
    "##laplace lm --  547.5497189073692\n",
    "unigram = lm.NGramLM(oov_train, 1)\n",
    "my_LM = lm.LaplaceLM(unigram, 0.4)\n",
    "\n",
    "##laplace lm -- 300.97971886348046\n",
    "bigram = lm.NGramLM(oov_train, 2)\n",
    "my_LM = lm.LaplaceLM(bigram, 0.004)\n",
    "\n",
    "## 164.2237198483916\n",
    "unigram = lm.LaplaceLM(lm.NGramLM(oov_train, 1),0.4)\n",
    "bigram = lm.NGramLM(oov_train, 2)\n",
    "trigram = lm.NGramLM(oov_train,3)    \n",
    "for alpha1 in np.arange(0.5,0.7,0.01):\n",
    "    for alpha2 in np.arange(0.2,0.3,0.01):\n",
    "        my_LM1 = lm.InterpolatedLM(bigram,unigram,alpha1)\n",
    "        my_LM = lm.InterpolatedLM(trigram, my_LM1, alpha2)\n",
    "        _snlp_lm = create_lm(_snlp_vocab)\n",
    "        print(alpha1,alpha2, lm.perplexity(_snlp_lm, _snlp_test_song_words))\n",
    "\n",
    "unigram = lm.LaplaceLM(lm.NGramLM(oov_train, 1),0.4)\n",
    "bigram = lm.NGramLM(oov_train, 2)\n",
    "trigram = lm.NGramLM(oov_train,3)\n",
    "my_LM1 = lm.InterpolatedLM(bigram,unigram,0.66)\n",
    "my_LM = lm.InterpolatedLM(trigram, my_LM1, 0.22)\n",
    "    \n",
    "##StupidBackoff -- 126.36654628232233 ///FALSE\n",
    "unigram = lm.LaplaceLM(lm.NGramLM(oov_train, 1),0.4)\n",
    "bigram = lm.NGramLM(oov_train, 2)\n",
    "my_LM = lm.StupidBackoff(bigram,unigram,0.999)\n",
    "\n",
    "##StupidBackoffNormalized -- 239.9377346450501\n",
    "unigram = lm.NGramLM(oov_train, 1)\n",
    "bigram = lm.NGramLM(oov_train, 2)\n",
    "my_LM = StupidBackoffNormalized(bigram, unigram, 0.01)\n",
    " \n",
    "##Interpolatedlm -- 188.57971535126373\n",
    "unigram = lm.LaplaceLm(lm.NGramLM(oov_train, 1),0.4)\n",
    "bigram = lm.NGramLM(oov_train, 2)\n",
    "my_LM = lm.InterpolatedLM(bigram,unigram,0.7167)\n",
    " \n",
    "#Interpolatedlm2 -- 164.220977639824\n",
    "unigram = lm.LaplaceLM(lm.NGramLM(oov_train, 1),0.4)\n",
    "bigram = lm.NGramLM(oov_train, 2)\n",
    "trigram = lm.NGramLM(oov_train, 3)\n",
    "for alpha1 in np.arange(0,1,0.1):\n",
    "    for alpha2 in np.arange(0,1,0.1):\n",
    "        my_LM = InterpolatedLM2 (trigram, bigram, unigram, alpha1, alpha2)\n",
    "        _snlp_lm = create_lm(_snlp_vocab)\n",
    "        print(alpha1,alpha2, lm.perplexity(_snlp_lm, _snlp_test_song_words))\n",
    "\n",
    "unigram = lm.LaplaceLM(lm.NGramLM(oov_train, 1),0.4)\n",
    "bigram = lm.LaplaceLM(lm.NGramLM(oov_train, 2),0.04)\n",
    "trigram = lm.NGramLM(oov_train, 3)\n",
    "my_LM = InterpolatedLM2 (trigram, bigram, unigram,0.22,0.52 )\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## StupidBackoffNormalized function \n",
    "from statnlpbook.lm import *\n",
    "\n",
    "class InterpolatedLM2(LanguageModel):\n",
    "    def __init__(self, main, backoff1,backoff2, alpha1, alpha2):\n",
    "        super().__init__(main.vocab, main.order)\n",
    "        self.main = main\n",
    "        self.backoff1 = backoff1\n",
    "        self.backoff2 = backoff2\n",
    "        self.alpha1 = alpha1\n",
    "        self.alpha2 = alpha2\n",
    "\n",
    "    def probability(self, word, *history):\n",
    "        return self.alpha1 * self.main.probability(word, *history) + \\\n",
    "                self.alpha2 * self.backoff1.probability(word, *history) + \\\n",
    "               (1.0 - self.alpha1 - self.alpha2) * self.backoff2.probability(word, *history)\n",
    "\n",
    "            \n",
    "class StupidBackoffNormalized(LanguageModel):\n",
    "    def __init__(self, main, backoff, alpha):\n",
    "        super().__init__(main.vocab, main.order)\n",
    "        self.main = main\n",
    "        self.backoff = backoff\n",
    "        self.alpha = alpha               \n",
    "\n",
    "    def probability(self, word, *history):\n",
    "        main_counts = self.main.counts((word,)+tuple(history))\n",
    "        main_norm = self.main.norm(history)        \n",
    "        backoff_order_diff = self.main.order - self.backoff.order\n",
    "        backoff_counts = self.backoff.counts((word,)+tuple(history[:-backoff_order_diff]))\n",
    "        backoff_norm = self.backoff.norm(history[:-backoff_order_diff])        \n",
    "        counts = main_counts + self.alpha * backoff_counts\n",
    "        norm = main_norm + self.alpha * backoff_norm\n",
    "        return counts / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You should improve this cell\n",
    "def create_lm(vocab):\n",
    "    \"\"\"\n",
    "    Return an instance of `lm.LanguageModel` defined over the given vocabulary.\n",
    "    Args:\n",
    "        vocab: the vocabulary the LM should be defined over. It is the union of the training and test words.\n",
    "    Returns:\n",
    "        a language model, instance of `lm.LanguageModel`.\n",
    "    \"\"\"\n",
    "    unigram = lm.LaplaceLM(lm.NGramLM(oov_train, 1),0.4)\n",
    "    bigram = lm.NGramLM(oov_train, 2)\n",
    "    my_LM1 = lm.InterpolatedLM(bigram,unigram,0.66)\n",
    "    trigram = lm.NGramLM(oov_train,3)\n",
    "    my_LM = lm.InterpolatedLM(trigram, my_LM1, 0.22)\n",
    "    # the unseen words can be achieved by subtract vocab with oov_vocab\n",
    "    return lm.OOVAwareLM(my_LM, vocab - oov_vocab)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 3</font>: Specify Test Data\n",
    "This cell defines the directory to load the test songs from. Currently, this points to the dev set but when we evaluate your notebook we will point this directory elsewhere and use a **hidden test set**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! SETUP 3\n",
    "_snlp_test_dir = _snlp_book_dir + \"/data/ohhla/dev\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 4</font>: Load Test Data and Prepare Language Model\n",
    "In this section we load the test data, prepare the reference vocabulary and then create your language model based on this vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! SETUP 4\n",
    "_snlp_test_song_words = ohhla.words(ohhla.load_all_songs(_snlp_test_dir))\n",
    "_snlp_test_vocab = set(_snlp_test_song_words)\n",
    "_snlp_dev_vocab = set(_snlp_dev_song_words)\n",
    "_snlp_train_vocab = set(_snlp_train_song_words)\n",
    "_snlp_vocab = _snlp_test_vocab | _snlp_train_vocab | _snlp_dev_vocab\n",
    "_snlp_lm = create_lm(_snlp_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 1</font>: Test Normalization (20 pts)\n",
    "Here we test whether the conditional distributions of your language model are properly normalized. If probabilities sum up to $1$ you get full points, you get half of the points if probabilities sum up to be smaller than 1, and 0 points otherwise. Due to floating point issues we will test with respect to a tolerance $\\epsilon$ (`_eps`).\n",
    "\n",
    "Points:\n",
    "* 10 pts: $\\leq 1 + \\epsilon$\n",
    "* 20 pts: $\\approx 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: 1.000000000000299, ~1: True, <=1: True\n",
      "Sum: 1.0000000000005882, ~1: True, <=1: True\n",
      "Sum: 0.9999999999997008, ~1: True, <=1: True\n"
     ]
    }
   ],
   "source": [
    "#! ASSESSMENT 1\n",
    "_snlp_test_token_indices = [100, 1000, 10000]\n",
    "_eps = 0.000001\n",
    "for i in _snlp_test_token_indices:\n",
    "    result = sum([_snlp_lm.probability(word, *_snlp_test_song_words[i-_snlp_lm.order+1:i]) for word in _snlp_vocab])\n",
    "    print(\"Sum: {sum}, ~1: {approx_1}, <=1: {leq_1}\".format(sum=result, \n",
    "                                                            approx_1=abs(result - 1.0) < _eps, \n",
    "                                                            leq_1=result - _eps <= 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above solution is marked with **\n",
    "<!-- ASSESSMENT 2: START_POINTS -->\n",
    "20\n",
    "<!-- ASSESSMENT 2: END_POINTS --> \n",
    "points **."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Assessment 2</font>: Apply to Test Data (50 pts)\n",
    "\n",
    "We assess how well your LM performs on some unseen test set. Perplexities are mapped to points as follows.\n",
    "\n",
    "* 0-10 pts: uniform perplexity > perplexity > 550, linear\n",
    "* 10-30 pts: 550 > perplexity > 140, linear\n",
    "* 30-50 pts: 140 > perplexity > 105, linear\n",
    "\n",
    "The **linear** mapping maps any perplexity value between the lower and upper bound linearly to a score. For example, if uniform perplexity is $U$ and your model's perplexity is $P\\leq550$, then your score is $10\\frac{P-U}{550-U}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164.2237198483916"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.perplexity(_snlp_lm, _snlp_test_song_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above solution is marked with **\n",
    "<!-- ASSESSMENT 3: START_POINTS -->\n",
    "0\n",
    "<!-- ASSESSMENT 3: END_POINTS --> points**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 2</font>: Describe your Approach\n",
    "\n",
    "< Enter a 500 words max description of your model and the way you trained and tuned it here >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 3</font>: Assess Description (30 pts) \n",
    "\n",
    "We will mark the description along the following dimensions: \n",
    "\n",
    "* Clarity (10pts: very clear, 0pts: we can't figure out what you did)\n",
    "* Creativity (10pts: we could not have come up with this, 0pts: Use the unigram model from the lecture notes)\n",
    "* Substance (10pts: implemented complex state-of-the-art LM, 0pts: Use the unigram model from the lecture notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above solution is marked with **\n",
    "<!-- ASSESSMENT 1: START_POINTS -->\n",
    "0\n",
    "<!-- ASSESSMENT 1: END_POINTS --> points**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
